## Nginx架构

nginx在unix系统上启动后，会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程，可以看到nginx是以多进程的方式来工作的。

**master进程主要用来管理worker进程：**

> * 接收外界的信号并向worker进程发送
> * 监控worker进程的运行状态
> * 异常情况下当worker进程退出后自动重启新的worker进程

基本的网络事件就放在worker进程中处理。

多个worker进程之间相互独立且对等，同等竞争来自客户端的请求。

一个请求只能在一个worker进程中处理，一个worker进程不可能处理其它worker进程的请求。

worker进程个数是可以设置的，一般设为与计算机CPU的核数一致。

#### Nginx进程模型：

![Nginx](imgs/nginx架构.png)

nginx启动后，master管理worker进程，所以外界只需给master进程发送信号就可以控制nginx了。

**reload nginx：**

nginx可以做到服务不中断的重启。当nginx收到重启命令时，首先master在收到信号后会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker发送信号告诉它们可以退出了。在新的worker启动后它们就开始接收新的请求，而老的worker在收到master的退出信号后就不在接收新的请求，并在当前进程所有请求处理完毕后就退出。

执行reload命令后会启动一个新的nginx进程，新的nginx进程在解析到reload参数后就知道命令的目的是控制nginx来重新加载配置文件了，它会向master进程发送信号，后续就如同上一段所说了。

**worker如何处理请求：**

worker进程之间是平等的，每个worker处理请求的机会一样。

HOW？每个worker都是从master进程fork过来的，在master里面，先建立好需要listen的socket（listenfd）之后再fork出多个worker。所有worker的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker在注册listenfd读事件前抢accept_mutex，抢到互斥锁的worker注册成功，在读事件里调用accept接受该连接。当一个worker在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样就构成了一个完整的请求。可以看到，一个请求完全由worker来处理，而且只在一个worker中处理。

**进程模型的好处：**

> * 对于每个worker来说，独立的进程不需要加锁，省掉了所带来的开销
> * 独立进程之间相互不影响，某个进程退出后其它进程还在工作，服务不中断而且master会很快启动新的worker
> * worker异常退出则说明出现了error，会导致当前worker上所以的请求失败，但不会影响到其它worker上的请求，降低了风险

#### Nginx事件处理模型：

nginx中的每个worker里只有一个主线程，所以采用了异步非阻塞的方式处理请求来实现高并发。因为若每个请求独占一个工作线程，当有几千个并发数时就同时有几千个线程在处理请求了，这些线程会带来非常大的内存占用，而且线程的上下文切换带来的CPU开销也很大，高并发也就无从说起了。

**一个请求的完整过程：**请求过来，建立连接，接收数据，处理数据，发送数据。这些操作具体到系统底层就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。阻塞调用会进入内核等待，cpu就会让出去给别人用了，对单线程的worker来说，显然不合适，当网络事件越多时，大家都在等待呢，cpu空闲下来没人用，cpu利用率自然上不去了，更别谈高并发了。好吧，你说加进程数，这跟apache的线程模型有什么区别，注意，别增加无谓的上下文切换。所以，在nginx里面，最忌讳阻塞的系统调用了。不要阻塞，那就非阻塞喽。非阻塞就是，事件没有准备好，马上返回EAGAIN，告诉你，事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做更多的事情了，但带来的开销也是不小的。所以，才会有了异步非阻塞的事件处理机制，具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制正好解决了我们上面的两个问题，拿epoll为例(在后面的例子中，我们多以epoll为例子，以代表这一类函数)，当事件没准备好时，放到epoll里面，事件准备好了，我们就去读写，当读写返回EAGAIN时，我们将它再次加入到epoll里面。这样，只要有事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才在epoll里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。



## Reference

[Nginx开发从入门到精通](http://tengine.taobao.org/book/)

